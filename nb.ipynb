{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  article dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision.utils import make_grid\n",
    "!pip install shap\n",
    "import shap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  loading training data\n",
    "training_set = Datasets.CIFAR10(root='./', download=True,\n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "#  loading validation data\n",
    "validation_set = Datasets.CIFAR10(root='./', download=True, train=False,\n",
    "                                  transform=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConvNet class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "    self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "    self.conv2 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "    self.batchnorm2 = nn.BatchNorm2d(8)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.conv3 = nn.Conv2d(8, 32, 3, padding=1)\n",
    "    self.batchnorm3 = nn.BatchNorm2d(32)\n",
    "    self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.batchnorm4 = nn.BatchNorm2d(32)\n",
    "    self.pool4 = nn.MaxPool2d(2)\n",
    "    self.conv5 = nn.Conv2d(32, 128, 3, padding=1)\n",
    "    self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "    self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "    self.batchnorm6 = nn.BatchNorm2d(128)\n",
    "    self.pool6 = nn.MaxPool2d(2)\n",
    "    self.conv7 = nn.Conv2d(128, 10, 1)\n",
    "    self.pool7 = nn.AvgPool2d(3)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #-------------\n",
    "    # INPUT\n",
    "    #-------------\n",
    "    x = x.view(-1, 3, 32, 32)\n",
    "    \n",
    "    #-------------\n",
    "    # LAYER 1\n",
    "    #-------------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = F.relu(output_1)\n",
    "    output_1 = self.batchnorm1(output_1)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 2\n",
    "    #-------------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = F.relu(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "    output_2 = self.batchnorm2(output_2)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 3\n",
    "    #-------------\n",
    "    output_3 = self.conv3(output_2)\n",
    "    output_3 = F.relu(output_3)\n",
    "    output_3 = self.batchnorm3(output_3)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 4\n",
    "    #-------------\n",
    "    output_4 = self.conv4(output_3)\n",
    "    output_4 = F.relu(output_4)\n",
    "    output_4 = self.pool4(output_4)\n",
    "    output_4 = self.batchnorm4(output_4)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 5\n",
    "    #-------------\n",
    "    output_5 = self.conv5(output_4)\n",
    "    output_5 = F.relu(output_5)\n",
    "    output_5 = self.batchnorm5(output_5)\n",
    "\n",
    "    #-------------\n",
    "    # LAYER 6\n",
    "    #-------------\n",
    "    output_6 = self.conv6(output_5)\n",
    "    output_6 = F.relu(output_6)\n",
    "    output_6 = self.pool6(output_6)\n",
    "    output_6 = self.batchnorm6(output_6)\n",
    "\n",
    "    #--------------\n",
    "    # OUTPUT LAYER\n",
    "    #--------------\n",
    "    output_7 = self.conv7(output_6)\n",
    "    output_7 = self.pool7(output_7)\n",
    "    output_7 = output_7.view(-1, 10)\n",
    "\n",
    "    return F.softmax(output_7, dim=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvolutionalNeuralNet():\n",
    "  def __init__(self, network):\n",
    "    self.network = network.to(device)\n",
    "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=1e-3)\n",
    "\n",
    "  def train(self, loss_function, epochs, batch_size, \n",
    "            training_set, validation_set):\n",
    "    \n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'training_recall_per_epoch': [],\n",
    "        'training_precision_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': [],\n",
    "        'validation_recall_per_epoch': [],\n",
    "        'validation_precision_per_epoch': []\n",
    "    } \n",
    "\n",
    "    #  defining weight initialization function\n",
    "    def init_weights(module):\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "      elif isinstance(module, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "\n",
    "    #  defining accuracy function\n",
    "    def accuracy(network, dataloader):\n",
    "      network.eval()\n",
    "      \n",
    "      all_predictions = []\n",
    "      all_labels = []\n",
    "\n",
    "      #  computing accuracy\n",
    "      total_correct = 0\n",
    "      total_instances = 0\n",
    "      for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        all_labels.extend(labels)\n",
    "        predictions = torch.argmax(network(images), dim=1)\n",
    "        all_predictions.extend(predictions)\n",
    "        correct_predictions = sum(predictions==labels).item()\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(images)\n",
    "      accuracy = round(total_correct/total_instances, 3)\n",
    "\n",
    "      #  computing recall and precision\n",
    "      true_positives = 0\n",
    "      false_negatives = 0\n",
    "      false_positives = 0\n",
    "      for idx in range(len(all_predictions)):\n",
    "        if all_predictions[idx].item()==1 and  all_labels[idx].item()==1:\n",
    "          true_positives+=1\n",
    "        elif all_predictions[idx].item()==0 and all_labels[idx].item()==1:\n",
    "          false_negatives+=1\n",
    "        elif all_predictions[idx].item()==1 and all_labels[idx].item()==0:\n",
    "          false_positives+=1\n",
    "      try:\n",
    "        recall = round(true_positives/(true_positives + false_negatives), 3)\n",
    "      except ZeroDivisionError:\n",
    "        recall = 0.0\n",
    "      try:\n",
    "        precision = round(true_positives/(true_positives + false_positives), 3)\n",
    "      except ZeroDivisionError:\n",
    "        precision = 0.0\n",
    "      return accuracy, recall, precision\n",
    "\n",
    "    #  initializing network weights\n",
    "    self.network.apply(init_weights)\n",
    "\n",
    "    #  creating dataloaders\n",
    "    train_loader = DataLoader(training_set, batch_size)\n",
    "    val_loader = DataLoader(validation_set, batch_size)\n",
    "\n",
    "    #  setting convnet to training mode\n",
    "    self.network.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      print(f'Epoch {epoch+1}/{epochs}')\n",
    "      train_losses = []\n",
    "\n",
    "      #  training\n",
    "      print('training...')\n",
    "      for images, labels in tqdm(train_loader):\n",
    "        #  sending data to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #  resetting gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        #  making predictions\n",
    "        predictions = self.network(images)\n",
    "        #  computing loss\n",
    "        loss = loss_function(predictions, labels)\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        #  computing gradients\n",
    "        loss.backward()\n",
    "        #  updating weights\n",
    "        self.optimizer.step()\n",
    "      with torch.no_grad():\n",
    "        print('deriving training accuracy...')\n",
    "        #  computing training accuracy\n",
    "        train_accuracy, train_recall, train_precision = accuracy(self.network, train_loader)\n",
    "        log_dict['training_accuracy_per_epoch'].append(train_accuracy)\n",
    "        log_dict['training_recall_per_epoch'].append(train_recall)\n",
    "        log_dict['training_precision_per_epoch'].append(train_precision)\n",
    "\n",
    "      #  validation\n",
    "      print('validating...')\n",
    "      val_losses = []\n",
    "\n",
    "      #  setting convnet to evaluation mode\n",
    "      self.network.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "          #  sending data to device\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          #  making predictions\n",
    "          predictions = self.network(images)\n",
    "          #  computing loss\n",
    "          val_loss = loss_function(predictions, labels)\n",
    "          log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "          val_losses.append(val_loss.item())\n",
    "        #  computing accuracy\n",
    "        print('deriving validation accuracy...')\n",
    "        val_accuracy, val_recall, val_precision = accuracy(self.network, val_loader)\n",
    "        log_dict['validation_accuracy_per_epoch'].append(val_accuracy)\n",
    "        log_dict['validation_recall_per_epoch'].append(val_recall)\n",
    "        log_dict['validation_precision_per_epoch'].append(val_precision)\n",
    "\n",
    "      train_losses = np.array(train_losses).mean()\n",
    "      val_losses = np.array(val_losses).mean()\n",
    "\n",
    "      print(f'training_loss: {round(train_losses, 4)}  training_accuracy: '+\n",
    "      f'{train_accuracy}  training_recall: {train_recall}  training_precision: {train_precision} *~* validation_loss: {round(val_losses, 4)} '+  \n",
    "      f'validation_accuracy: {val_accuracy}  validation_recall: {val_recall}  validation_precision: {val_precision}\\n')\n",
    "      \n",
    "    return log_dict\n",
    "\n",
    "  def predict(self, x):\n",
    "    return self.network(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = ConvolutionalNeuralNet(ConvNet())\n",
    "\n",
    "log_dict = model.train(nn.CrossEntropyLoss(), epochs=15, batch_size=64, \n",
    "                       training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a mask"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  defining dataset class\n",
    "class CustomMask(Dataset):\n",
    "  def __init__(self, data, transforms=None):\n",
    "    self.data = data\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = self.data[idx]\n",
    "\n",
    "    if self.transforms!=None:\n",
    "      image = self.transforms(image)\n",
    "    return image\n",
    "    \n",
    "#  creating explainer mask\n",
    "mask = validation_set.data[:200]\n",
    "\n",
    "#  turning mask to pytorch dataset\n",
    "mask = CustomMask(mask, transforms=transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explainability function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_shap(image_array, mask, model):\n",
    "  \"\"\"\n",
    "  This function performs model explainability\n",
    "  by producing shap plots for a data instance\n",
    "  \"\"\"\n",
    "  #  converting image to tensor\n",
    "  image = transforms.ToTensor()(image_array)\n",
    "  image = image.to(device)\n",
    "\n",
    "  #-----------------\n",
    "  #  CLASSIFICATION\n",
    "  #-----------------\n",
    "  #  creating a mapping of classes to labels\n",
    "  label_dict = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
    "                5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "\n",
    "  #  utilizing the model for classification\n",
    "  with torch.no_grad():\n",
    "    prediction = torch.argmax(model(image), dim=1).item()\n",
    "\n",
    "  #  displaying model classification\n",
    "  print(f'prediction: {label_dict[prediction]}')\n",
    "\n",
    "  #----------------\n",
    "  #  EXPLANABILITY\n",
    "  #----------------\n",
    "  #  creating dataloader for mask\n",
    "  mask_loader = DataLoader(mask, batch_size=200)\n",
    "\n",
    "  #  creating explainer for model behaviour\n",
    "  for images in mask_loader:\n",
    "    images = images.to(device)\n",
    "    explainer = shap.DeepExplainer(model, images)\n",
    "    break\n",
    "\n",
    "  #  deriving shap values for image of interest based on model behaviour\n",
    "  shap_values = explainer.shap_values(image.view(-1, 3, 32, 32))\n",
    "\n",
    "  #  preparing for visualization by changing channel arrangement\n",
    "  shap_numpy = [np.swapaxes(np.swapaxes(x, 1, -1), 1, 2) for x in shap_values]\n",
    "  image_numpy = np.swapaxes(np.swapaxes(image.view(-1, 3, 32, 32).cpu().numpy(), 1, -1), 1, 2)\n",
    "\n",
    "  #  producing shap plots\n",
    "  shap.image_plot(shap_numpy, image_numpy, show=False, labels= ['airplane', 'automobile', 'bird', \n",
    "                                                                'cat', 'deer', 'dog','frog',\n",
    "                                                                'horse', 'ship', 'truck'])\n",
    "  pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Interpreting SHAP plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_shap(validation_set.data[-150], mask, model.network)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using important images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_shap_util(filepath, mask, model):\n",
    "  \"\"\"\n",
    "  This function performs model explainability\n",
    "  by producing shap plots for a data instance\n",
    "  \"\"\"\n",
    "  #  reading image and converting to tensor\n",
    "  image = cv2.imread(filepath)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image, (32, 32))\n",
    "  image = transforms.ToTensor()(image)\n",
    "  image = image.to(device)\n",
    "\n",
    "  #-----------------\n",
    "  #  CLASSIFICATION\n",
    "  #-----------------\n",
    "  #  creating a mapping of classes to labels  \n",
    "  label_dict = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
    "                5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "\n",
    "  #  utilizing the model for classification\n",
    "  prediction = torch.argmax(model(image), dim=1).item()\n",
    "\n",
    "  #  displaying model classification\n",
    "  print(f'prediction: {label_dict[prediction]}')\n",
    "\n",
    "  #----------------\n",
    "  #  EXPLANABILITY\n",
    "  #----------------\n",
    "  #  creating dataloader for mask\n",
    "  mask_loader = DataLoader(mask, batch_size=200)\n",
    "\n",
    "  #  creating explainer for model behaviour\n",
    "  for images in mask_loader:\n",
    "    images = images.to(device)\n",
    "    explainer = shap.DeepExplainer(model, images)\n",
    "    break\n",
    "\n",
    "  #  deriving shap values for image of interest based on model behaviour\n",
    "  shap_values = explainer.shap_values(image.view(-1, 3, 32, 32))\n",
    "\n",
    "  #  preparing for visualization by changing channel arrangement\n",
    "  shap_numpy = [np.swapaxes(np.swapaxes(x, 1, -1), 1, 2) for x in shap_values]\n",
    "  test_numpy = np.swapaxes(np.swapaxes(image.view(-1, 3, 32, 32).cpu().numpy(), 1, -1), 1, 2)\n",
    "\n",
    "  #  producing shap plots\n",
    "  shap.image_plot(shap_numpy, test_numpy, show=False, labels= ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                                                               'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "  \n",
    "  pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  using the extended explainability function\n",
    "plot_shap_util('image.jpg', mask, model.network)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}